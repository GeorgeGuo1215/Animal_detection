# ğŸ¯ SAMç‰¹å¾æ•è·å¿«é€ŸæŒ‡å—

## âœ… æˆåŠŸæ•è·SAMè¾“å‡ºï¼

æ ¹æ®ä½ çš„è¿è¡Œç»“æœï¼Œå·²ç»æˆåŠŸæ•è·åˆ°SAMæ¨¡å‹çš„è¾“å‡ºï¼š

### æ•è·åˆ°çš„ç‰¹å¾

1. **PATCHESç‰¹å¾** (å±€éƒ¨è£å‰ª)
   - å½¢çŠ¶: `[6, 1024, 10, 10]`
   - 6ä¸ªå±€éƒ¨patchï¼Œæ¯ä¸ª1024é€šé“ï¼Œ10x10ç©ºé—´åˆ†è¾¨ç‡

2. **BASEç‰¹å¾** (å…¨å±€å›¾åƒ)
   - å½¢çŠ¶: `[1, 1024, 16, 16]`
   - 1ä¸ªå…¨å±€è§†å›¾ï¼Œ1024é€šé“ï¼Œ16x16ç©ºé—´åˆ†è¾¨ç‡

è¿™ä¸¤ä¸ªå°±æ˜¯SAMæ¨¡å‹çš„**åŸå§‹è¾“å‡º**ï¼Œåœ¨ç»è¿‡CLIPå’ŒProjectorå¤„ç†åå˜æˆï¼š
- BASE: `[1, 256, 1280]` (reshapeå)
- PATCHES: `[6, 100, 1280]` (reshapeå)

---

## ğŸš€ ä½¿ç”¨æ­¥éª¤

### Step 1: æ•è·SAMç‰¹å¾

ä¿®å¤BFloat16é—®é¢˜åï¼Œé‡æ–°è¿è¡Œï¼š

```bash
cd F:\BaiduNetdiskDownload\æ¸¯åŸå¤§\deepseek-ocr\DeepSeek-OCR\DeepSeek-OCR-master\DeepSeek-OCR-hf
python run_with_direct_capture.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
âœ“ æ•è·åˆ° 2 ä¸ªvisionç‰¹å¾
ä¿å­˜ç‰¹å¾:
[0] ../../output/feature_0_ImageEncoderViT_6x1024x10x10.npy
[1] ../../output/feature_1_ImageEncoderViT_1x1024x16x16.npy
```

### Step 2: åˆ†æSAMç‰¹å¾

```bash
python analyze_sam_features.py
```

è¿™ä¼šç”Ÿæˆï¼š
- ğŸ“Š å¤šé€šé“ç‰¹å¾å¯è§†åŒ–
- ğŸ“ˆ ç»Ÿè®¡å¯¹æ¯”å›¾
- ğŸ“„ è¯¦ç»†åˆ†ææŠ¥å‘Š

---

## ğŸ“¦ ç”Ÿæˆçš„æ–‡ä»¶è¯´æ˜

### ä¸»è¦è¾“å‡ºæ–‡ä»¶

```
output/
â”œâ”€â”€ feature_0_ImageEncoderViT_6x1024x10x10.npy      # PATCHES SAMè¾“å‡º
â”œâ”€â”€ feature_1_ImageEncoderViT_1x1024x16x16.npy      # BASE SAMè¾“å‡º
â”œâ”€â”€ feature_0_ImageEncoderViT_vis.png                # å¿«é€Ÿå¯è§†åŒ–
â”œâ”€â”€ feature_1_ImageEncoderViT_vis.png                # å¿«é€Ÿå¯è§†åŒ–
â”œâ”€â”€ analysis_batch0_feature_0_*.png                  # è¯¦ç»†å¤šé€šé“åˆ†æ
â”œâ”€â”€ feature_statistics_comparison.png                # ç»Ÿè®¡å¯¹æ¯”
â””â”€â”€ sam_features_report.txt                          # æ–‡æœ¬æŠ¥å‘Š
```

---

## ğŸ’» ä½¿ç”¨SAMç‰¹å¾çš„ä»£ç ç¤ºä¾‹

### åŸºç¡€åŠ è½½

```python
import numpy as np

# åŠ è½½PATCHESç‰¹å¾
patches = np.load('output/feature_0_ImageEncoderViT_6x1024x10x10.npy')
print(f"PATCHESå½¢çŠ¶: {patches.shape}")  # [6, 1024, 10, 10]

# åŠ è½½BASEç‰¹å¾
base = np.load('output/feature_1_ImageEncoderViT_1x1024x16x16.npy')
print(f"BASEå½¢çŠ¶: {base.shape}")  # [1, 1024, 16, 16]
```

### å¯è§†åŒ–å•ä¸ªé€šé“

```python
import matplotlib.pyplot as plt

# å¯è§†åŒ–BASEçš„ç¬¬ä¸€ä¸ªé€šé“
plt.figure(figsize=(10, 10))
plt.imshow(base[0, 0, :, :], cmap='viridis')
plt.colorbar()
plt.title('BASE Feature - Channel 0')
plt.savefig('base_channel_0.png')
```

### åˆ†æç©ºé—´æ¿€æ´»æ¨¡å¼

```python
import numpy as np
import matplotlib.pyplot as plt

# è®¡ç®—æ¯ä¸ªç©ºé—´ä½ç½®çš„å¹³å‡æ¿€æ´»
base_spatial = base[0].mean(axis=0)  # å¯¹1024ä¸ªé€šé“æ±‚å¹³å‡ -> [16, 16]

plt.figure(figsize=(8, 8))
plt.imshow(base_spatial, cmap='hot', interpolation='nearest')
plt.colorbar(label='Mean Activation')
plt.title('BASE Spatial Activation Map')
plt.xlabel('Width')
plt.ylabel('Height')
plt.savefig('base_spatial_activation.png')
```

### åˆ†æé€šé“é‡è¦æ€§

```python
# è®¡ç®—æ¯ä¸ªé€šé“çš„æ€»æ¿€æ´»å¼ºåº¦
channel_importance = base[0].reshape(1024, -1).mean(axis=1)

# æ‰¾å‡ºæœ€é‡è¦çš„10ä¸ªé€šé“
top_10_channels = np.argsort(channel_importance)[-10:][::-1]

print("æœ€é‡è¦çš„10ä¸ªé€šé“:")
for i, ch in enumerate(top_10_channels):
    print(f"  {i+1}. Channel {ch}: {channel_importance[ch]:.4f}")

# å¯è§†åŒ–
plt.figure(figsize=(12, 4))
plt.plot(channel_importance)
plt.scatter(top_10_channels, channel_importance[top_10_channels], 
           c='red', s=100, zorder=5)
plt.xlabel('Channel Index')
plt.ylabel('Mean Activation')
plt.title('Channel Importance')
plt.grid(True, alpha=0.3)
plt.savefig('channel_importance.png')
```

### æ¯”è¾ƒBASEå’ŒPATCHES

```python
# è®¡ç®—BASEå’Œç¬¬ä¸€ä¸ªPATCHçš„ç‰¹å¾ç›¸ä¼¼åº¦
from scipy.spatial.distance import cosine

base_vec = base[0].flatten()
patch1_vec = patches[0].flatten()

# è°ƒæ•´é•¿åº¦
min_len = min(len(base_vec), len(patch1_vec))
base_vec = base_vec[:min_len]
patch1_vec = patch1_vec[:min_len]

similarity = 1 - cosine(base_vec, patch1_vec)
print(f"BASE vs PATCH1 ç›¸ä¼¼åº¦: {similarity:.4f}")

# è®¡ç®—æ‰€æœ‰PATCHä¹‹é—´çš„ç›¸ä¼¼åº¦çŸ©é˜µ
n_patches = patches.shape[0]
similarity_matrix = np.zeros((n_patches, n_patches))

for i in range(n_patches):
    for j in range(n_patches):
        vec_i = patches[i].flatten()
        vec_j = patches[j].flatten()
        similarity_matrix[i, j] = 1 - cosine(vec_i, vec_j)

plt.figure(figsize=(8, 6))
plt.imshow(similarity_matrix, cmap='coolwarm', vmin=0, vmax=1)
plt.colorbar(label='Cosine Similarity')
plt.title('Patch-to-Patch Similarity Matrix')
plt.xlabel('Patch Index')
plt.ylabel('Patch Index')
plt.savefig('patch_similarity.png')
```

### ç‰¹å¾èšåˆ

```python
# å°†æ‰€æœ‰PATCHç‰¹å¾èšåˆ
patches_mean = patches.mean(axis=0)  # [1024, 10, 10]
patches_max = patches.max(axis=0)    # [1024, 10, 10]

# å¯è§†åŒ–èšåˆåçš„ç©ºé—´æ¨¡å¼
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

axes[0].imshow(patches_mean.mean(axis=0), cmap='viridis')
axes[0].set_title('PATCHES Mean Pooling')
axes[0].axis('off')

axes[1].imshow(patches_max.mean(axis=0), cmap='viridis')
axes[1].set_title('PATCHES Max Pooling')
axes[1].axis('off')

plt.savefig('patches_pooling.png')
```

---

## ğŸ” ç‰¹å¾çš„ç‰©ç†æ„ä¹‰

### BASEç‰¹å¾ `[1, 1024, 16, 16]`

- **ç”¨é€”**: å…¨å±€æ–‡æ¡£ç†è§£
- **åŒ…å«ä¿¡æ¯**: 
  - æ•´ä½“å¸ƒå±€ç»“æ„
  - æ®µè½åˆ†å¸ƒ
  - å›¾æ–‡æ··æ’æ¨¡å¼
- **åˆ†è¾¨ç‡**: 16x16ï¼ˆç›¸å¯¹ä½åˆ†è¾¨ç‡ï¼Œå…³æ³¨å…¨å±€ï¼‰

### PATCHESç‰¹å¾ `[6, 1024, 10, 10]`

- **ç”¨é€”**: å±€éƒ¨ç»†èŠ‚è¯†åˆ«
- **åŒ…å«ä¿¡æ¯**:
  - æ–‡å­—ç»†èŠ‚
  - è¾¹ç¼˜å’Œç¬”ç”»
  - å±€éƒ¨çº¹ç†
- **åˆ†è¾¨ç‡**: 10x10ï¼ˆæ¯ä¸ªpatchçš„å±€éƒ¨ç‰¹å¾ï¼‰
- **æ•°é‡**: 6ä¸ªä¸åŒçš„å±€éƒ¨åŒºåŸŸ

---

## ğŸ¨ é«˜çº§åº”ç”¨ç¤ºä¾‹

### 1. æ–‡æ¡£åŒºåŸŸæ£€æµ‹

```python
import cv2

# ä½¿ç”¨BASEç‰¹å¾çš„ç©ºé—´æ¿€æ´»æ¥æ£€æµ‹é‡è¦åŒºåŸŸ
base_activation = base[0].mean(axis=0)  # [16, 16]

# ä¸Šé‡‡æ ·åˆ°åŸå§‹å›¾åƒå¤§å°
from scipy.ndimage import zoom
upsampled = zoom(base_activation, (800/16, 600/16))

# åº”ç”¨é˜ˆå€¼
threshold = upsampled.mean() + upsampled.std()
mask = upsampled > threshold

# å¯è§†åŒ–
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.imshow(upsampled, cmap='hot')
plt.title('Activation Heatmap')
plt.colorbar()

plt.subplot(1, 2, 2)
plt.imshow(mask, cmap='gray')
plt.title('Important Regions')

plt.savefig('region_detection.png')
```

### 2. ç‰¹å¾é™ç»´å¯è§†åŒ– (t-SNE)

```python
from sklearn.manifold import TSNE

# å°†æ‰€æœ‰ç‰¹å¾å±•å¹³
all_features = []
labels = []

# BASE
base_flat = base.reshape(1, -1)  # [1, 1024*16*16]
all_features.append(base_flat[0])
labels.append('BASE')

# PATCHES
for i in range(patches.shape[0]):
    patch_flat = patches[i].reshape(-1)  # [1024*10*10]
    all_features.append(patch_flat)
    labels.append(f'PATCH-{i}')

all_features = np.array(all_features)

# t-SNEé™ç»´åˆ°2D
tsne = TSNE(n_components=2, random_state=42)
features_2d = tsne.fit_transform(all_features)

# å¯è§†åŒ–
plt.figure(figsize=(10, 8))
for i, label in enumerate(labels):
    color = 'red' if label == 'BASE' else 'blue'
    marker = 'o' if label == 'BASE' else '^'
    plt.scatter(features_2d[i, 0], features_2d[i, 1], 
               c=color, marker=marker, s=200, alpha=0.7, label=label)

plt.legend()
plt.title('SAM Features in 2D Space (t-SNE)')
plt.xlabel('Dimension 1')
plt.ylabel('Dimension 2')
plt.grid(True, alpha=0.3)
plt.savefig('features_tsne.png')
```

### 3. åˆ›å»ºè‡ªå®šä¹‰ç‰¹å¾å›¾

```python
def create_feature_map(feature, method='mean'):
    """
    ä»SAMç‰¹å¾åˆ›å»ºå•é€šé“ç‰¹å¾å›¾
    
    Args:
        feature: [B, C, H, W]
        method: 'mean', 'max', 'std', 'pca'
    
    Returns:
        feature_map: [H, W]
    """
    if method == 'mean':
        return feature.mean(axis=(0, 1))  # å¯¹Bå’ŒCæ±‚å¹³å‡
    elif method == 'max':
        return feature.max(axis=(0, 1))
    elif method == 'std':
        return feature.std(axis=(0, 1))
    elif method == 'pca':
        from sklearn.decomposition import PCA
        B, C, H, W = feature.shape
        flat = feature.reshape(B*C, H*W).T  # [H*W, B*C]
        pca = PCA(n_components=1)
        result = pca.fit_transform(flat)  # [H*W, 1]
        return result.reshape(H, W)

# ä½¿ç”¨
base_mean = create_feature_map(base, 'mean')
base_max = create_feature_map(base, 'max')
base_std = create_feature_map(base, 'std')

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

axes[0].imshow(base_mean, cmap='viridis')
axes[0].set_title('Mean')

axes[1].imshow(base_max, cmap='viridis')
axes[1].set_title('Max')

axes[2].imshow(base_std, cmap='viridis')
axes[2].set_title('Std Dev')

plt.savefig('feature_maps_comparison.png')
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šBFloat16é”™è¯¯

**è§£å†³**: å·²åœ¨ä¿®å¤ç‰ˆè„šæœ¬ä¸­å¤„ç†ï¼Œä¼šè‡ªåŠ¨è½¬æ¢ä¸ºFloat32

### é—®é¢˜ï¼šå†…å­˜ä¸è¶³

**è§£å†³**: åªä¿å­˜ä½ éœ€è¦çš„ç‰¹å¾

```python
# åœ¨æ•è·è„šæœ¬ä¸­æ·»åŠ è¿‡æ»¤
if output.shape[1] == 1024:  # åªä¿å­˜1024é€šé“çš„
    sam_outputs.append(output)
```

### é—®é¢˜ï¼šç‰¹å¾å¤ªå¤§

**è§£å†³**: ä¿å­˜é™é‡‡æ ·ç‰ˆæœ¬

```python
# ä¿å­˜æ—¶é™é‡‡æ ·
tensor_downsampled = tensor[:, ::4, :, :]  # åªä¿å­˜æ¯4ä¸ªé€šé“
np.save(file, tensor_downsampled.numpy())
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

1. **SAMè®ºæ–‡**: "Segment Anything" - Meta AI Research
2. **DeepSeek-OCR**: ç»“åˆSAM+CLIPçš„å¤šæ¨¡æ€OCR
3. **ç‰¹å¾å¯è§†åŒ–**: ä½¿ç”¨t-SNE, PCAç­‰é™ç»´æŠ€æœ¯

---

## âœ¨ æ€»ç»“

ä½ ç°åœ¨å¯ä»¥ï¼š

1. âœ… æ•è·SAMæ¨¡å‹çš„åŸå§‹è¾“å‡º
2. âœ… ç†è§£BASEå’ŒPATCHESçš„åŒºåˆ«
3. âœ… åˆ†æå’Œå¯è§†åŒ–ç‰¹å¾
4. âœ… ä½¿ç”¨ç‰¹å¾è¿›è¡Œä¸‹æ¸¸ä»»åŠ¡

**ä¸‹ä¸€æ­¥**: æ ¹æ®ä½ çš„å…·ä½“éœ€æ±‚ï¼Œä½¿ç”¨è¿™äº›ç‰¹å¾è¿›è¡Œï¼š
- æ–‡æ¡£å¸ƒå±€åˆ†æ
- åŒºåŸŸæ£€æµ‹
- å›¾åƒæ£€ç´¢
- ç‰¹å¾å­¦ä¹ 

ç¥å®éªŒé¡ºåˆ©ï¼ğŸ‰




















